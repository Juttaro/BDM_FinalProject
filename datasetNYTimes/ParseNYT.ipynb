{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10522f590>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePersons(df):\n",
    "    personsCollection = open('PersonsCollection.txt', 'a')\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df[i])):\n",
    "            if df[i][j][1] == 'persons':\n",
    "                person = re.sub(r'[^a-zA-Z]', ' ', df[i][j][3]).lower()\n",
    "                personsCollection.write(person+'\\n')\n",
    "\n",
    "def parseSubject(df):\n",
    "    subjectCollection = open('SubjectCollection.txt', 'a')\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df[i])):\n",
    "            if df[i][j][1] == 'subject':\n",
    "                subject = re.sub(r'[^a-zA-Z]', ' ', df[i][j][3]).lower()\n",
    "                subjectCollection.write(subject+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesuttaro/Desktop/Spring 2017/Big Data - 59927/BDM_FinalProject/BDM_FinalProject/datasetNYTimes\n"
     ]
    }
   ],
   "source": [
    "#archive = open('archivejan1.json', 'r')\n",
    "# os.listdir('~')\n",
    "# df.show()\n",
    "# df.printSchema()\n",
    "cwd = os.getcwd()\n",
    "print cwd\n",
    "for i in  glob.glob(cwd+'/archive*'):\n",
    "    df = spark.read.json(i)\n",
    "    df = df.select('response.docs.keywords')\n",
    "    df = df.first()[0]\n",
    "    parsePersons(df)\n",
    "    parseSubject(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = df.select('response.docs.keywords')\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = df.first()[0]\n",
    "# print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapper(line):\n",
    "    for word in line:\n",
    "        yield(word.lower(),1)\n",
    "\n",
    "def reducer(line):\n",
    "    yield (word, sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
